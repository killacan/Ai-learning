{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c91a4f45-e87c-431f-9693-15e266e30c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df73bb7-4868-4985-bf47-6b8cbf8c1208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar \n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9fd5e-04ba-4881-9d95-0826d3f10182",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "### Creating tensors\n",
    "\n",
    "PyTorch tensors are created using `torch.Tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505b8f18-1fb5-462e-8c6a-656d9c45cb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebee3d42-a12f-4d98-87ab-a3f334dad6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca42066-6f8a-475a-8384-c6fb31d17da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b65fa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7,8],[9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac681e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0614da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d40daff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor\n",
    "TENSOR = torch.tensor([[[1,2,3],[4,5,6],[7,8,9],[10,11,12]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0df8af81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8053b944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cf1033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213dc61",
   "metadata": {},
   "source": [
    "## Random tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors ful of random numbers and then adjust tnose random numbers to better represent the data.\n",
    "\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5777306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7852, 0.7186],\n",
       "        [0.6046, 0.6680],\n",
       "        [0.4200, 0.5813]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3, 2)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb7be6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8849, 0.0765, 0.0113, 0.3023, 0.5851, 0.0747, 0.0816, 0.6373,\n",
       "          0.3180, 0.3304],\n",
       "         [0.5147, 0.9759, 0.8302, 0.6936, 0.8955, 0.1823, 0.7187, 0.3525,\n",
       "          0.4199, 0.4459],\n",
       "         [0.4317, 0.6712, 0.6239, 0.0217, 0.6664, 0.8714, 0.7806, 0.6490,\n",
       "          0.8438, 0.8944],\n",
       "         [0.3469, 0.7297, 0.2735, 0.7582, 0.2943, 0.6631, 0.0541, 0.7953,\n",
       "          0.4233, 0.7899],\n",
       "         [0.4664, 0.9556, 0.5691, 0.7591, 0.2225, 0.2541, 0.4868, 0.1348,\n",
       "          0.1728, 0.2249],\n",
       "         [0.3418, 0.6750, 0.0302, 0.1205, 0.2843, 0.6657, 0.7936, 0.7754,\n",
       "          0.3756, 0.5736],\n",
       "         [0.0259, 0.0613, 0.7092, 0.4984, 0.5675, 0.4882, 0.0204, 0.5318,\n",
       "          0.9713, 0.3276],\n",
       "         [0.8532, 0.7147, 0.0154, 0.3804, 0.1349, 0.4866, 0.5992, 0.1692,\n",
       "          0.8874, 0.3175],\n",
       "         [0.5085, 0.7116, 0.1214, 0.4783, 0.1299, 0.2763, 0.5904, 0.2963,\n",
       "          0.3009, 0.0574],\n",
       "         [0.9146, 0.3484, 0.1312, 0.3762, 0.8647, 0.3552, 0.1281, 0.9557,\n",
       "          0.1567, 0.6623]],\n",
       "\n",
       "        [[0.6038, 0.6950, 0.7242, 0.3304, 0.2105, 0.6569, 0.9117, 0.7305,\n",
       "          0.6712, 0.9346],\n",
       "         [0.4600, 0.5194, 0.4812, 0.7848, 0.5795, 0.4316, 0.5356, 0.7384,\n",
       "          0.1985, 0.7187],\n",
       "         [0.5755, 0.9642, 0.0912, 0.3017, 0.8499, 0.5925, 0.2534, 0.0334,\n",
       "          0.2759, 0.4803],\n",
       "         [0.9326, 0.5469, 0.2203, 0.0572, 0.2189, 0.7104, 0.3854, 0.7673,\n",
       "          0.8449, 0.8747],\n",
       "         [0.6351, 0.8870, 0.7742, 0.7194, 0.0406, 0.6617, 0.1213, 0.5990,\n",
       "          0.7179, 0.7319],\n",
       "         [0.9844, 0.1843, 0.2831, 0.7373, 0.6803, 0.7271, 0.3696, 0.8281,\n",
       "          0.9370, 0.1614],\n",
       "         [0.8760, 0.3634, 0.6541, 0.5268, 0.7559, 0.7928, 0.7618, 0.9147,\n",
       "          0.9678, 0.5473],\n",
       "         [0.8383, 0.5768, 0.8884, 0.7652, 0.1053, 0.9412, 0.6134, 0.4490,\n",
       "          0.2747, 0.9491],\n",
       "         [0.6514, 0.8680, 0.4049, 0.5887, 0.4707, 0.4269, 0.4989, 0.4380,\n",
       "          0.6772, 0.1636],\n",
       "         [0.5382, 0.8493, 0.2341, 0.5163, 0.1601, 0.1968, 0.8089, 0.1201,\n",
       "          0.2605, 0.4989]],\n",
       "\n",
       "        [[0.2120, 0.6377, 0.6586, 0.9474, 0.0696, 0.9845, 0.5213, 0.8752,\n",
       "          0.4883, 0.1457],\n",
       "         [0.6649, 0.2795, 0.9531, 0.4558, 0.7133, 0.0226, 0.0587, 0.8891,\n",
       "          0.9854, 0.9607],\n",
       "         [0.0833, 0.3053, 0.5468, 0.9536, 0.1081, 0.1345, 0.9730, 0.2459,\n",
       "          0.2565, 0.0020],\n",
       "         [0.5634, 0.6910, 0.7180, 0.3020, 0.5760, 0.6441, 0.3378, 0.3144,\n",
       "          0.3468, 0.9586],\n",
       "         [0.0983, 0.4088, 0.6208, 0.9835, 0.5943, 0.5837, 0.2809, 0.8161,\n",
       "          0.9009, 0.8786],\n",
       "         [0.6460, 0.0277, 0.4888, 0.8396, 0.9902, 0.3065, 0.9243, 0.7215,\n",
       "          0.8527, 0.2599],\n",
       "         [0.9901, 0.0517, 0.8220, 0.3435, 0.1924, 0.8270, 0.7239, 0.7179,\n",
       "          0.1740, 0.6599],\n",
       "         [0.8389, 0.1845, 0.9843, 0.0403, 0.8362, 0.6413, 0.2145, 0.4542,\n",
       "          0.7821, 0.1784],\n",
       "         [0.0402, 0.1399, 0.6193, 0.7908, 0.8568, 0.3619, 0.8420, 0.8004,\n",
       "          0.9406, 0.9978],\n",
       "         [0.0243, 0.8632, 0.8213, 0.1282, 0.8268, 0.0792, 0.9549, 0.6119,\n",
       "          0.6366, 0.7288]],\n",
       "\n",
       "        [[0.9139, 0.5364, 0.0170, 0.4157, 0.2219, 0.5795, 0.5152, 0.9136,\n",
       "          0.4156, 0.1558],\n",
       "         [0.6098, 0.5008, 0.5634, 0.5241, 0.2992, 0.3186, 0.4741, 0.5886,\n",
       "          0.1686, 0.0059],\n",
       "         [0.7067, 0.7837, 0.9403, 0.0891, 0.4744, 0.2891, 0.1472, 0.3766,\n",
       "          0.5258, 0.8464],\n",
       "         [0.3689, 0.3613, 0.7682, 0.8977, 0.0518, 0.3965, 0.7413, 0.6916,\n",
       "          0.8685, 0.5247],\n",
       "         [0.4975, 0.5168, 0.7285, 0.7713, 0.8732, 0.1209, 0.9713, 0.6491,\n",
       "          0.9063, 0.4573],\n",
       "         [0.9999, 0.2952, 0.4193, 0.4560, 0.3850, 0.0061, 0.1851, 0.0031,\n",
       "          0.1287, 0.9006],\n",
       "         [0.5976, 0.5971, 0.0921, 0.9608, 0.9035, 0.9206, 0.4407, 0.1806,\n",
       "          0.0059, 0.8795],\n",
       "         [0.6538, 0.2294, 0.8990, 0.5572, 0.3265, 0.2961, 0.4183, 0.4877,\n",
       "          0.4335, 0.4573],\n",
       "         [0.8243, 0.3406, 0.6908, 0.8060, 0.2727, 0.6560, 0.8150, 0.3694,\n",
       "          0.8271, 0.6707],\n",
       "         [0.8230, 0.1503, 0.2093, 0.8667, 0.4291, 0.8316, 0.5034, 0.7573,\n",
       "          0.3060, 0.0811]],\n",
       "\n",
       "        [[0.1100, 0.1293, 0.8677, 0.8469, 0.9481, 0.1219, 0.6530, 0.8814,\n",
       "          0.7380, 0.9770],\n",
       "         [0.9560, 0.6522, 0.2720, 0.1805, 0.9793, 0.1588, 0.9240, 0.4316,\n",
       "          0.8944, 0.4394],\n",
       "         [0.8507, 0.2697, 0.6045, 0.4556, 0.0355, 0.9842, 0.4597, 0.3574,\n",
       "          0.3052, 0.4129],\n",
       "         [0.5534, 0.8455, 0.7189, 0.2065, 0.0612, 0.0962, 0.9653, 0.5836,\n",
       "          0.9341, 0.5107],\n",
       "         [0.5838, 0.4287, 0.9888, 0.0272, 0.9624, 0.3722, 0.1850, 0.2801,\n",
       "          0.8674, 0.4682],\n",
       "         [0.1850, 0.7431, 0.2791, 0.1381, 0.0873, 0.1338, 0.6289, 0.0760,\n",
       "          0.4788, 0.5678],\n",
       "         [0.1819, 0.6695, 0.0071, 0.8891, 0.9980, 0.9194, 0.8780, 0.6652,\n",
       "          0.9240, 0.9134],\n",
       "         [0.8334, 0.9848, 0.7515, 0.5950, 0.7698, 0.3912, 0.3826, 0.3332,\n",
       "          0.3607, 0.4140],\n",
       "         [0.3215, 0.3231, 0.1478, 0.4275, 0.3215, 0.5203, 0.3297, 0.0089,\n",
       "          0.5065, 0.6372],\n",
       "         [0.2814, 0.6832, 0.6728, 0.8191, 0.8558, 0.9268, 0.0346, 0.0890,\n",
       "          0.5699, 0.9783]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size=(5,10,10))\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36468464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor with all zeroes\n",
    "zeroes = torch.zeros(size=(3,4))\n",
    "zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad32d43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor with all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0745c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49027a83",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7934dfaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8346993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdbf1035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0875, 0.5864, 0.1330, 0.1509],\n",
       "        [0.1909, 0.4477, 0.3149, 0.5273],\n",
       "        [0.0997, 0.0467, 0.6257, 0.1868]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5038e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0875, 0.5864, 0.1330, 0.1509],\n",
      "        [0.1909, 0.4477, 0.3149, 0.5273],\n",
      "        [0.0997, 0.0467, 0.6257, 0.1868]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a591065",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c2d8400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf26bb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e5b037e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c05b04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out PyTorch in-built functions\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8465d",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "two main ways of preforming multiplication in neural networks and deep learning:\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy. \n",
    "1. The **inner dimensions** must match:\n",
    "// @ stands for matrix multiplication\n",
    "* `(3, 2) @ (3, 2)` won't work\n",
    "* `(2, 3) @ (3, 2)` will work\n",
    "* `(3, 2) @ (2, 3)` will work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad2c7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06ff9d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cacd8dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ffffff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 + 2*2 + 3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd3f825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: user 1.53 ms, sys: 248 µs, total: 1.77 ms\n",
      "Wall time: 8.13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c785416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 205 µs, sys: 0 ns, total: 205 µs\n",
      "Wall time: 159 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26a7c190",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9100/792290316.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtensor_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtensor_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.mm is the same as torch.matmul.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "### One of the most common errors in deep learning: is shape errors\n",
    "tensor_A = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "tensor_B = torch.tensor([[7,10], [8,11], [9, 12]])\n",
    "torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe0ac2",
   "metadata": {},
   "source": [
    "to fix the tensor shape error, we can manipulate the shape of our tensors using transpose\n",
    "\n",
    "a **transpose** switches the axes or dimensions of a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2194ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d435f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68453ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d0d62",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, ect (tensor aggregation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c44f942f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5bf6b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a4834d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf373b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the mean - torch.mean() function requires a tensor of float32 \n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3207108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa428f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tenosor that has the minimum value with argmin() returns index position of target tensor were the minimum value occurs\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca5b6835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d8a1aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the position in the tensor that has the maximum value with argmax() \n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef32123",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input to a defined shape\n",
    "* View - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "baa3a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d582efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an extra dimension\n",
    "x_reshaped = x.reshape(1,9) \n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3455862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "X_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f36e37c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack the tensors on top of each other\n",
    "X_stacked[0][0] = 2.\n",
    "X_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7acff72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 9])\n",
      "Squeezed tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Squeezed shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() - removes all single dimensions from a target tensor\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimensions from x_reshaped\n",
    "x_squeezed = torch.squeeze(x_reshaped)\n",
    "print(f\"Squeezed tensor: {x_squeezed}\")\n",
    "print(f\"Squeezed shape: {x_squeezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8ade091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "Unsqueezed tensor: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Unsqueezed shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "#torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim (dimension)\n",
    "print(f\"Previous target: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# Add an extra dimension with unsqueeze()\n",
    "x_unsqueezed = torch.unsqueeze(x_squeezed, dim=0)\n",
    "print(f\"Unsqueezed tensor: {x_unsqueezed}\")\n",
    "print(f\"Unsqueezed shape: {x_unsqueezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50286b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of the target tensor\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [height, width, channels]\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.clone().detach().permute(2, 0, 1) # [channels, height, width]\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2df4a624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8908745050430298 and 0.8908745050430298\n",
      "1.0 and 0.8908745050430298\n"
     ]
    }
   ],
   "source": [
    "print(f\"{x_original[0, 0, 0]} and {x_permuted[0, 0, 0]}\")\n",
    "x_original[0, 0, 0] = 1.\n",
    "print(f\"{x_original[0, 0, 0]} and {x_permuted[0, 0, 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200538d",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "812a6ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "x, x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c39d3f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets index on the new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4814e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets index on the middle bracket (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc37a33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets index on the most inner bracket (dim=2)\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc630497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use : to select all of a target dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea56d57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of 0th and 1st dimensions but only index 2 of the 2nd dimension\n",
    "x[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15202e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of the 0th dimension but only the 1 index value of the 1st and 2nd dimensions\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b4cf15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index 0 of 0th and 1st dimension and all values of the 2nd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2b37cb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index on x to return 9\n",
    "x[0, 2, 2]\n",
    "\n",
    "#Index on x to return 3, 6, 9\n",
    "x[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4a1b2",
   "metadata": {},
   "source": [
    "## PyTorch tensors and NumPy\n",
    "\n",
    "NumPy is a popular scientific python numerical computing library. \n",
    "\n",
    "because of this, PyTorch has functionality to interact with it. \n",
    "\n",
    "* Data in  NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "18c02df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # warning, when converting from numpy to pytorch. Pytorch reflects numpy's default data type of float64 unless otherwise specified.\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4654a44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the value of array, what will this do to tensor?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9978f5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b5c635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to `numpy_tensor`?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e04d1",
   "metadata": {},
   "source": [
    "## Reproducibility (trying to take the random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**\n",
    "\n",
    "Essentially what the random seed does is \"flavor\" the randomness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bf167e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0343, 0.5219, 0.6714, 0.3202],\n",
      "        [0.0520, 0.5426, 0.8707, 0.2362],\n",
      "        [0.6460, 0.1370, 0.1854, 0.3756]])\n",
      "tensor([[0.1047, 0.6746, 0.3582, 0.9834],\n",
      "        [0.3040, 0.9458, 0.9787, 0.2299],\n",
      "        [0.7712, 0.0128, 0.8977, 0.5978]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e21fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# lets make some random but reproducible tensors\n",
    "import torch\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED) # must be called each time you want to reset the random seed.\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17352d4b",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on GPU's (and making faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory (good). \n",
    "\n",
    "### Getting a GPU\n",
    "\n",
    "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
    "2. Use your own GPU-  takes a little bit of setup and requires the investment of purchasing a GPU, there's lots of options. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39afb0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 12 17:13:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "|  0%   30C    P8     9W / 250W |      9MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:06:00.0  On |                  N/A |\n",
      "|  0%   52C    P0    68W / 250W |    841MiB / 11264MiB |      9%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1759      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      1759      G   /usr/lib/xorg/Xorg                413MiB |\n",
      "|    1   N/A  N/A      2374      G   cinnamon                           43MiB |\n",
      "|    1   N/A  N/A      6293      G   ...RendererForSitePerProcess      181MiB |\n",
      "|    1   N/A  N/A      7626      G   /usr/lib/firefox/firefox          128MiB |\n",
      "|    1   N/A  N/A      8115      G   ...011848821875541864,131072        9MiB |\n",
      "|    1   N/A  N/A     12904      G   ...e/Steam/ubuntu12_32/steam       14MiB |\n",
      "|    1   N/A  N/A     12976      G   ...ef_log.txt --shared-files       42MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f55e7f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5fdee",
   "metadata": {},
   "source": [
    "For PyTorch since it's capable of running compute on the GPU or CPU, it's best practice to set up device agnostic code\n",
    "E.g. run on GPU if available, else default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "69e3816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d0a65d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111895e",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and models) on the GPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "450cf530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# create a tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "#Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65224c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434dddb",
   "metadata": {},
   "source": [
    "### 4. Moving Tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d897ae62",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9100/1385885994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If tensor is on GPU, can transform it to NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can transform it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "736f0095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fix GPU tensor with NumPy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1ace8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6feec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e01ec2cc26a0c6789886845faf816ea15502e8dc00af526f71bc8d49d052cd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
